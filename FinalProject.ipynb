{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FinalProject.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+Vh3Bo/MvcW6P70lSmw9k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zSBXGX0ughu","executionInfo":{"status":"ok","timestamp":1657803655895,"user_tz":240,"elapsed":23380,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"12faad4d-97e7-4121-9ef5-beadd9d029c1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from zipfile import ZipFile\n","file_name = \"/content/drive/MyDrive/DeepMecProject/datasetFER2013/archive5.zip\"\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print(\"Done\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MyPlx_yuk0C","executionInfo":{"status":"ok","timestamp":1657803695309,"user_tz":240,"elapsed":4940,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"9e3f452e-16a2-45d6-8d20-1979efb69c60"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Done\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54BEExn7tTpb","executionInfo":{"status":"ok","timestamp":1657793461712,"user_tz":240,"elapsed":3967,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"368b34e0-52a5-404e-a5d9-3482d65a6398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","import json\n","import os\n","from tqdm.auto import tqdm\n","import shutil\n","import random\n","import cv2\n","\n","# Instalar la librería de Kaggle para descargar datasets\n","!pip install kaggle\n","\n","# Antes de descargar el dataset, es importante definir las credenciales para acceder al API de Kaggle\n","!mkdir ~/.kaggle\n","!touch ~/.kaggle/kaggle.json\n","\n","# Puedes crear tu propio token y username de la API de Kaggle en https://www.kaggle.com/\n","api_token = {\"username\":\"benjaminvillegas\",\"key\":\"51aee955395f28ce555fbc0a8abb4481\"}\n","\n","# Crear un archivo con las credenciales, de tal forma que kaggle pueda leerlas facilmente\n","with open('/root/.kaggle/kaggle.json', 'w') as file:\n","    json.dump(api_token, file)\n","\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","%cd /content\n","\n","# Comprobar si el conjunto de datos ya se ha descargado\n","if not os.path.exists('./affectnethq'):\n","  os.makedirs('affectnethq')\n","else: \n","  !rm -rf affectnethq\n","\n","# Descargar un dataset desde Kaggle\n","#!kaggle datasets download -d tunhunhminh/demodata -p city_problems\n","!kaggle datasets download -d tom99763/affectnethq\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSp1By2Ovzyi","executionInfo":{"status":"ok","timestamp":1657793541919,"user_tz":240,"elapsed":74390,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"73b3b307-0520-4d83-da10-a29ab446fb2f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Downloading affectnethq.zip to /content\n","100% 8.09G/8.12G [01:12<00:00, 147MB/s]\n","100% 8.12G/8.12G [01:13<00:00, 119MB/s]\n"]}]},{"cell_type":"code","source":["# Descomprimir dataset \n","!unzip -qn '/content/affectnethq.zip' -d /content/affectnethq > /dev/null\n","!rm /content/affectnethq.zip"],"metadata":{"id":"nvskTOqGxQ1d","executionInfo":{"status":"ok","timestamp":1657793980561,"user_tz":240,"elapsed":82068,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["categories = [\"surprise\",\"happy\",\"anger\",\"disgust\",\"fear\",\"sad\",\"neutral\"]\n","#dataset = pd.read_csv('/content/affectnethq/labels.csv')"],"metadata":{"id":"SzQGs9Sljwes","executionInfo":{"status":"ok","timestamp":1657803715134,"user_tz":240,"elapsed":376,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dataset[\"label\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fG7nmnUyH-rV","executionInfo":{"status":"ok","timestamp":1657794000661,"user_tz":240,"elapsed":3,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"7bf2d995-9461-4221-ea7f-4a77d2a99a3d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'surprise'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["cad=dataset[\"pth\"][0]\n","s=cad.split('/')\n","cad2=s[1]\n","cad2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"10koTTBrZ79Q","executionInfo":{"status":"ok","timestamp":1657794002647,"user_tz":240,"elapsed":4,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"bce67769-9735-450a-f983-94f8c6bbe28b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'image0000006.jpg'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#movemos cada imagen a su carpeta respectiva segun el archivo csv\n","for idx, sample in enumerate(dataset[\"label\"]):\n","  s=dataset[\"pth\"][idx]\n","  cad=s.split('/')\n","  direc=cad[1]\n","  shutil.move(\"/content/affectnethq/\"+dataset[\"pth\"][idx],\"/content/affectnethq/\"+dataset[\"label\"][idx]+\"/\"+direc)\n"],"metadata":{"id":"DciwhTwjdssQ","executionInfo":{"status":"ok","timestamp":1657794006174,"user_tz":240,"elapsed":1305,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#comprobamos que el nuero de imagenes corresponda a cierta categoria segun e\n","import os\n","initial_count = 0\n","dir = \"/content/affectnethq/sad\"\n","for path in os.listdir(dir):\n","    if os.path.isfile(os.path.join(dir, path)):\n","        initial_count += 1\n","print(initial_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugREBh16Kq4X","executionInfo":{"status":"ok","timestamp":1657794008673,"user_tz":240,"elapsed":308,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"e122b1ef-0300-4b71-ac95-f125217e2061"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["3344\n"]}]},{"cell_type":"code","source":["count=0\n","for i, sample in enumerate(dataset[\"label\"]):\n","  if sample=='sad':\n","    count=count+1\n","print(count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ci93AjDwK3kB","executionInfo":{"status":"ok","timestamp":1657794011007,"user_tz":240,"elapsed":316,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"91355608-d7c4-4935-f3f3-9772d4d15b4c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["3352\n"]}]},{"cell_type":"code","source":["#dividimos el dataset\n","!pip install split-folders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_dQbB2Mi4u3","executionInfo":{"status":"ok","timestamp":1657803730163,"user_tz":240,"elapsed":8297,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"fab59a5e-532f-4c53-b4e6-05ed8fce2cbc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import json\n","import os\n","from tqdm.auto import tqdm\n","import shutil\n","import random\n","import cv2"],"metadata":{"id":"aNI2c3APztv6","executionInfo":{"status":"ok","timestamp":1657803828357,"user_tz":240,"elapsed":1568,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import splitfolders  \n","\n","#Dividir una carpeta en 80% train y 20% test\n","splitfolders.ratio(\"/content/affectnethq\", output=\"/content/dataAffect2\", seed=1337, ratio=(.7, .15, .15), group_prefix=None) # default values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"wJDlBCgXjMiP","executionInfo":{"status":"error","timestamp":1657803830872,"user_tz":240,"elapsed":360,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"7c712384-6250-4b6e-bd91-161ce43c2c81"},"execution_count":9,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-11e4d873ee63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Dividir una carpeta en 80% train y 20% test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplitfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/affectnethq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/dataAffect2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# default values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(input, output, seed, ratio, group_prefix, move)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`ratio` should\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/splitfolders/split.py\u001b[0m in \u001b[0;36mcheck_input_format\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' Your relative path cannot be found from the current working directory \"{Path.cwd()}\".'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The provided input folder \"/content/affectnethq\" does not exists."]}]},{"cell_type":"code","source":["import splitfolders  \n","\n","#Dividir una carpeta en 80% train y 20% test\n","splitfolders.ratio(\"/content/archive5/emotion_faces\", output=\"/content/ck+fer2013\", seed=1337, ratio=(.7, .15, .15), group_prefix=None) # default values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJwfSWT8vFZE","executionInfo":{"status":"ok","timestamp":1657803840477,"user_tz":240,"elapsed":3368,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"1ddcae98-d3e5-4492-d7bb-3dcb938661e4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Copying files: 18980 files [00:03, 5919.21 files/s]\n"]}]},{"cell_type":"code","source":["# Buscar dentro los directorios\n","data_dir = '/content/ck+fer2013'\n","print(os.listdir(data_dir))\n","classes_train = os.listdir(data_dir + \"/train\")\n","classes_valid = os.listdir(data_dir + \"/val\")\n","classes_test = os.listdir(data_dir + \"/test\")\n","print(f'Train Classes - {classes_train}')\n","print(f'Validation Classes - {classes_valid}')\n","print(f'Test Classes - {classes_test}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLrd_qCekIPR","executionInfo":{"status":"ok","timestamp":1657803852319,"user_tz":240,"elapsed":502,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"da91696b-4ea8-48eb-bc39-59c29accb7ce"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['val', 'test', 'train']\n","Train Classes - ['sad', 'angry', 'surprise', 'neutral', 'disgust', 'happy', 'fear']\n","Validation Classes - ['sad', 'angry', 'surprise', 'neutral', 'disgust', 'happy', 'fear']\n","Test Classes - ['sad', 'angry', 'surprise', 'neutral', 'disgust', 'happy', 'fear']\n"]}]},{"cell_type":"code","source":["import zipfile \n","import tensorflow as tf \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator \n","from tensorflow.keras import layers \n","from tensorflow.keras import Model \n","import matplotlib.pyplot as plt"],"metadata":{"id":"uBjchqnMloJG","executionInfo":{"status":"ok","timestamp":1657803861501,"user_tz":240,"elapsed":2868,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Todas las imágenes seran divididas entre el maximo valor por canal, por lo que quedaran rescaladas entre el 0 y 1. \n","train_datagen = ImageDataGenerator(rescale=1/255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Tamaño del lote (imágenes a procesar por el modelo al mismo tiempo)\n","BATCH_SIZE = 62\n","TRAINSET_PATH=\"/content/ck+fer2013/train\"\n","VALIDSET_PATH = \"/content/ck+fer2013/val\"\n","TESTSET_PATH = \"/content/ck+fer2013/test\"\n","\n","\n","# Importar datos desde los directorios y convertirlos en lotes de tensores\n","train_data = train_datagen.flow_from_directory(TRAINSET_PATH,\n","                                               batch_size=BATCH_SIZE, # tamaño del lote\n","                                               color_mode='grayscale',\n","                                               target_size=(48, 48), # convertir todas las imágenes a 224 x 224\n","                                               class_mode=\"categorical\", # tipo de problema, usar 'binary' si tuviesemos dos clases\n","                                               seed=42) # semilla para generar las mismas selecciones durante los experimentos\n","\n","valid_data = valid_datagen.flow_from_directory(VALIDSET_PATH,\n","                                               batch_size=BATCH_SIZE,\n","                                               color_mode='grayscale',\n","                                               target_size=(48, 48),\n","                                               class_mode=\"categorical\",\n","                                               seed=42)\n","test_data = test_datagen.flow_from_directory(TESTSET_PATH,\n","                                               batch_size=BATCH_SIZE,\n","                                               color_mode='grayscale',\n","                                               target_size=(48, 48),\n","                                               class_mode=\"categorical\",\n","                                               seed=42)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtCSix0nml8n","executionInfo":{"status":"ok","timestamp":1657813509609,"user_tz":240,"elapsed":1836,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"08f7a21a-0638-4cf8-ae16-a1afc8de0afd"},"execution_count":175,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 13283 images belonging to 7 classes.\n","Found 2844 images belonging to 7 classes.\n","Found 2853 images belonging to 7 classes.\n"]}]},{"cell_type":"code","source":["#cargamos el modelo efficientNet de keras\n","from tensorflow.keras.applications import ResNet50\n","img_input = tf.keras.layers.Input(shape=(48, 48,1))\n","img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])  \n","\n","base_model = ResNet50(include_top = False, weights = None,input_tensor=img_conc, classes=7)#classes=7\n","\n"],"metadata":{"id":"5d-KJzOwnkTK","executionInfo":{"status":"ok","timestamp":1657813541229,"user_tz":240,"elapsed":3625,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["cfg = base_model.get_config()\n","cfg['layers'][0]['config']['batch_input_shape'] = (None, 48, 48, 1)\n","resnet_model = Model.from_config(cfg) \n","\n","\n","for i, layer in enumerate(resnet_model.layers):\n","    if i == 1:\n","#         print('up')\n","        new_weights = base_model.layers[i].get_weights()[0].sum(axis=2, keepdims=True)\n","        resnet_model.set_weights([new_weights])\n","        layer.trainable = False\n","    else: \n","        break"],"metadata":{"id":"CDaux6kegeBa","executionInfo":{"status":"ok","timestamp":1657812710453,"user_tz":240,"elapsed":1828,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":162,"outputs":[]},{"cell_type":"code","source":["#congelamos layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","base_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzKdMD8HsrEa","executionInfo":{"status":"ok","timestamp":1657812632758,"user_tz":240,"elapsed":2254,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"0496a6a1-7ba4-4560-a971-c04c9fa35963"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_21 (InputLayer)          [(None, 48, 48, 1)]  0           []                               \n","                                                                                                  \n"," concatenate_20 (Concatenate)   (None, 48, 48, 3)    0           ['input_21[0][0]',               \n","                                                                  'input_21[0][0]',               \n","                                                                  'input_21[0][0]']               \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['concatenate_20[0][0]']         \n","                                                                                                  \n"," conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n","                                                                                                  \n"," conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n","                                                                                                  \n"," conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n","                                                                                                  \n"," pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n","                                                                  'conv2_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n","                                                                                                  \n"," conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n","                                                                                                  \n"," conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n","                                                                  'conv2_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n","                                                                                                  \n"," conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n","                                                                                                  \n"," conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n","                                                                  'conv2_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n","                                                                                                  \n"," conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n","                                                                  'conv3_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n","                                                                                                  \n"," conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n","                                                                                                  \n"," conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n","                                                                  'conv3_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n","                                                                                                  \n"," conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n","                                                                                                  \n"," conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n","                                                                  'conv3_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n","                                                                                                  \n"," conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n","                                                                  'conv3_block4_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n","                                                                                                  \n"," conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n","                                                                  'conv4_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n","                                                                                                  \n"," conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n","                                                                                                  \n"," conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n","                                                                  'conv4_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n","                                                                                                  \n"," conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n","                                                                                                  \n"," conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n","                                                                  'conv4_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n","                                                                                                  \n"," conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n","                                                                                                  \n"," conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n","                                                                  'conv4_block4_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n","                                                                                                  \n"," conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n","                                                                  'conv4_block5_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n","                                                                                                  \n"," conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n","                                                                                                  \n"," conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n","                                                                  'conv4_block6_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n","                                                                                                  \n"," conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n","                                                                                                  \n"," conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n","                                                                                                  \n"," conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n","                                                                  'conv5_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n","                                                                                                  \n"," conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n","                                                                                                  \n"," conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n","                                                                  'conv5_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n","                                                                                                  \n"," conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n","                                                                                                  \n"," conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n","                                                                  'conv5_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 23,587,712\n","Trainable params: 0\n","Non-trainable params: 23,587,712\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["last_layers=base_model.get_layer('conv2_block1_out')\n","last_output=last_layers.output"],"metadata":{"id":"WhHE5lnKDuBg","executionInfo":{"status":"ok","timestamp":1657813561255,"user_tz":240,"elapsed":331,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":178,"outputs":[]},{"cell_type":"code","source":["#x = tf.keras.layers.Dense(128, activation=\"relu\")(last_output)\n","x = tf.keras.layers.Flatten()(last_output)\n","\n","x = tf.keras.layers.Dropout(0.5)(x)#(last_output)\n","#x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n","#x = tf.keras.layers.Flatten()(x)\n","\n","# Add a final sigmoid layer with 1 node for classification output\n","predictions = tf.keras.layers.Dense(7, activation=\"softmax\")(x)\n","model_final = Model(base_model.input, predictions)"],"metadata":{"id":"Ndy0XBwIs87y","executionInfo":{"status":"ok","timestamp":1657813641283,"user_tz":240,"elapsed":440,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["model_final.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.002),loss='categorical_crossentropy',metrics=['accuracy'])               "],"metadata":{"id":"FXz7uY03w6rS","executionInfo":{"status":"ok","timestamp":1657813651534,"user_tz":240,"elapsed":527,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":180,"outputs":[]},{"cell_type":"code","source":["model_final.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p67jHNtcRnmz","executionInfo":{"status":"ok","timestamp":1657813653203,"user_tz":240,"elapsed":415,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"9822ccef-e4d2-4d88-abf4-f9ed601679bb"},"execution_count":181,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_19\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_25 (InputLayer)          [(None, 48, 48, 1)]  0           []                               \n","                                                                                                  \n"," concatenate_24 (Concatenate)   (None, 48, 48, 3)    0           ['input_25[0][0]',               \n","                                                                  'input_25[0][0]',               \n","                                                                  'input_25[0][0]']               \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['concatenate_24[0][0]']         \n","                                                                                                  \n"," conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n","                                                                                                  \n"," conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n","                                                                                                  \n"," conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n","                                                                                                  \n"," pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n","                                                                  'conv2_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n","                                                                                                  \n"," flatten_19 (Flatten)           (None, 36864)        0           ['conv2_block1_out[0][0]']       \n","                                                                                                  \n"," dropout_19 (Dropout)           (None, 36864)        0           ['flatten_19[0][0]']             \n","                                                                                                  \n"," dense_19 (Dense)               (None, 7)            258055      ['dropout_19[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 344,711\n","Trainable params: 343,303\n","Non-trainable params: 1,408\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["mn_history = model_final.fit(train_data,validation_data = valid_data, epochs = 150)#,steps_per_epoch = 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBGpt-BJxv3H","executionInfo":{"status":"ok","timestamp":1657815410262,"user_tz":240,"elapsed":1216039,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"f21e77fa-097b-4e57-ff3b-6fdba3755afc"},"execution_count":182,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","215/215 [==============================] - 17s 58ms/step - loss: 4.1307 - accuracy: 0.2038 - val_loss: 14.4874 - val_accuracy: 0.1709\n","Epoch 2/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.8517 - accuracy: 0.2536 - val_loss: 5.9556 - val_accuracy: 0.1776\n","Epoch 3/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.8223 - accuracy: 0.2700 - val_loss: 5.1449 - val_accuracy: 0.2124\n","Epoch 4/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.7984 - accuracy: 0.2809 - val_loss: 5.6795 - val_accuracy: 0.1955\n","Epoch 5/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.7885 - accuracy: 0.2872 - val_loss: 3.0643 - val_accuracy: 0.2416\n","Epoch 6/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.7734 - accuracy: 0.2917 - val_loss: 2.4052 - val_accuracy: 0.2873\n","Epoch 7/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.7627 - accuracy: 0.3014 - val_loss: 4.1348 - val_accuracy: 0.2507\n","Epoch 8/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.7493 - accuracy: 0.3041 - val_loss: 3.0782 - val_accuracy: 0.2672\n","Epoch 9/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.7338 - accuracy: 0.3178 - val_loss: 1.8677 - val_accuracy: 0.3224\n","Epoch 10/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.7248 - accuracy: 0.3157 - val_loss: 3.8057 - val_accuracy: 0.2004\n","Epoch 11/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.7161 - accuracy: 0.3246 - val_loss: 2.2974 - val_accuracy: 0.3101\n","Epoch 12/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.7142 - accuracy: 0.3233 - val_loss: 2.9801 - val_accuracy: 0.2827\n","Epoch 13/150\n","215/215 [==============================] - 12s 57ms/step - loss: 1.7004 - accuracy: 0.3373 - val_loss: 2.7048 - val_accuracy: 0.2968\n","Epoch 14/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.6900 - accuracy: 0.3332 - val_loss: 2.3558 - val_accuracy: 0.2894\n","Epoch 15/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.6935 - accuracy: 0.3350 - val_loss: 2.8100 - val_accuracy: 0.2542\n","Epoch 16/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.6744 - accuracy: 0.3462 - val_loss: 2.7989 - val_accuracy: 0.3530\n","Epoch 17/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.6704 - accuracy: 0.3504 - val_loss: 1.6395 - val_accuracy: 0.3404\n","Epoch 18/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.6632 - accuracy: 0.3615 - val_loss: 2.5582 - val_accuracy: 0.3379\n","Epoch 19/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.6609 - accuracy: 0.3528 - val_loss: 2.7086 - val_accuracy: 0.3745\n","Epoch 20/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.6449 - accuracy: 0.3565 - val_loss: 1.6654 - val_accuracy: 0.3745\n","Epoch 21/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.6470 - accuracy: 0.3604 - val_loss: 2.4054 - val_accuracy: 0.3411\n","Epoch 22/150\n","215/215 [==============================] - 10s 49ms/step - loss: 1.6335 - accuracy: 0.3670 - val_loss: 2.8423 - val_accuracy: 0.2637\n","Epoch 23/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.6314 - accuracy: 0.3656 - val_loss: 4.5329 - val_accuracy: 0.2468\n","Epoch 24/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.6273 - accuracy: 0.3672 - val_loss: 3.3612 - val_accuracy: 0.2932\n","Epoch 25/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.6312 - accuracy: 0.3661 - val_loss: 4.7936 - val_accuracy: 0.3530\n","Epoch 26/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.6182 - accuracy: 0.3748 - val_loss: 1.6404 - val_accuracy: 0.3572\n","Epoch 27/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.6043 - accuracy: 0.3813 - val_loss: 2.3571 - val_accuracy: 0.3442\n","Epoch 28/150\n","215/215 [==============================] - 10s 49ms/step - loss: 1.5998 - accuracy: 0.3786 - val_loss: 1.7104 - val_accuracy: 0.3495\n","Epoch 29/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.6058 - accuracy: 0.3815 - val_loss: 1.8676 - val_accuracy: 0.3724\n","Epoch 30/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5967 - accuracy: 0.3768 - val_loss: 2.6177 - val_accuracy: 0.3594\n","Epoch 31/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5867 - accuracy: 0.3834 - val_loss: 1.8316 - val_accuracy: 0.3214\n","Epoch 32/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5878 - accuracy: 0.3825 - val_loss: 1.6529 - val_accuracy: 0.3724\n","Epoch 33/150\n","215/215 [==============================] - 10s 49ms/step - loss: 1.5841 - accuracy: 0.3864 - val_loss: 2.4136 - val_accuracy: 0.3871\n","Epoch 34/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5714 - accuracy: 0.3947 - val_loss: 1.7299 - val_accuracy: 0.3903\n","Epoch 35/150\n","215/215 [==============================] - 10s 49ms/step - loss: 1.5789 - accuracy: 0.3943 - val_loss: 2.4072 - val_accuracy: 0.3977\n","Epoch 36/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5732 - accuracy: 0.3940 - val_loss: 1.6487 - val_accuracy: 0.3956\n","Epoch 37/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5641 - accuracy: 0.3968 - val_loss: 1.6325 - val_accuracy: 0.4233\n","Epoch 38/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.5572 - accuracy: 0.4009 - val_loss: 1.7335 - val_accuracy: 0.3544\n","Epoch 39/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5593 - accuracy: 0.4003 - val_loss: 1.6184 - val_accuracy: 0.3928\n","Epoch 40/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5630 - accuracy: 0.3962 - val_loss: 1.9294 - val_accuracy: 0.3569\n","Epoch 41/150\n","215/215 [==============================] - 10s 49ms/step - loss: 1.5505 - accuracy: 0.3965 - val_loss: 2.1473 - val_accuracy: 0.3351\n","Epoch 42/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.5608 - accuracy: 0.3956 - val_loss: 1.5469 - val_accuracy: 0.3889\n","Epoch 43/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.5593 - accuracy: 0.4003 - val_loss: 1.9177 - val_accuracy: 0.3158\n","Epoch 44/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.5500 - accuracy: 0.3989 - val_loss: 3.4165 - val_accuracy: 0.2985\n","Epoch 45/150\n","215/215 [==============================] - 12s 57ms/step - loss: 1.5452 - accuracy: 0.4049 - val_loss: 2.8303 - val_accuracy: 0.3653\n","Epoch 46/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.5437 - accuracy: 0.4022 - val_loss: 1.6667 - val_accuracy: 0.4132\n","Epoch 47/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.5316 - accuracy: 0.4120 - val_loss: 1.6325 - val_accuracy: 0.4314\n","Epoch 48/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5400 - accuracy: 0.4067 - val_loss: 2.2924 - val_accuracy: 0.4124\n","Epoch 49/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.5350 - accuracy: 0.4117 - val_loss: 2.2267 - val_accuracy: 0.3608\n","Epoch 50/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5476 - accuracy: 0.4056 - val_loss: 1.7575 - val_accuracy: 0.4008\n","Epoch 51/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5374 - accuracy: 0.4133 - val_loss: 13.0826 - val_accuracy: 0.2342\n","Epoch 52/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5379 - accuracy: 0.4121 - val_loss: 2.1289 - val_accuracy: 0.3622\n","Epoch 53/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5255 - accuracy: 0.4141 - val_loss: 2.0733 - val_accuracy: 0.3428\n","Epoch 54/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5344 - accuracy: 0.4156 - val_loss: 2.5836 - val_accuracy: 0.3467\n","Epoch 55/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.5349 - accuracy: 0.4159 - val_loss: 4.9339 - val_accuracy: 0.3186\n","Epoch 56/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.5384 - accuracy: 0.4016 - val_loss: 21.4571 - val_accuracy: 0.2433\n","Epoch 57/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5260 - accuracy: 0.4137 - val_loss: 2.5472 - val_accuracy: 0.3748\n","Epoch 58/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5375 - accuracy: 0.4145 - val_loss: 1.6648 - val_accuracy: 0.4279\n","Epoch 59/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5352 - accuracy: 0.4082 - val_loss: 2.6272 - val_accuracy: 0.3643\n","Epoch 60/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.5219 - accuracy: 0.4181 - val_loss: 1.9295 - val_accuracy: 0.3660\n","Epoch 61/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.5210 - accuracy: 0.4181 - val_loss: 1.4761 - val_accuracy: 0.4191\n","Epoch 62/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5094 - accuracy: 0.4232 - val_loss: 2.1279 - val_accuracy: 0.3695\n","Epoch 63/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5296 - accuracy: 0.4156 - val_loss: 2.6196 - val_accuracy: 0.3636\n","Epoch 64/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5332 - accuracy: 0.4188 - val_loss: 2.7312 - val_accuracy: 0.3383\n","Epoch 65/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5266 - accuracy: 0.4151 - val_loss: 3.9390 - val_accuracy: 0.2440\n","Epoch 66/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.5202 - accuracy: 0.4131 - val_loss: 1.8156 - val_accuracy: 0.4279\n","Epoch 67/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5193 - accuracy: 0.4193 - val_loss: 3.2537 - val_accuracy: 0.3302\n","Epoch 68/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5028 - accuracy: 0.4226 - val_loss: 2.2030 - val_accuracy: 0.3312\n","Epoch 69/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5177 - accuracy: 0.4190 - val_loss: 1.7958 - val_accuracy: 0.4037\n","Epoch 70/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5149 - accuracy: 0.4200 - val_loss: 1.4334 - val_accuracy: 0.4599\n","Epoch 71/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5114 - accuracy: 0.4193 - val_loss: 1.8479 - val_accuracy: 0.4110\n","Epoch 72/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5039 - accuracy: 0.4272 - val_loss: 4.8435 - val_accuracy: 0.3119\n","Epoch 73/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.5078 - accuracy: 0.4246 - val_loss: 2.0460 - val_accuracy: 0.3875\n","Epoch 74/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.4983 - accuracy: 0.4265 - val_loss: 1.8312 - val_accuracy: 0.4269\n","Epoch 75/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5069 - accuracy: 0.4211 - val_loss: 7.6478 - val_accuracy: 0.2240\n","Epoch 76/150\n","215/215 [==============================] - 10s 47ms/step - loss: 1.5032 - accuracy: 0.4241 - val_loss: 3.2142 - val_accuracy: 0.3748\n","Epoch 77/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5118 - accuracy: 0.4245 - val_loss: 3.7593 - val_accuracy: 0.3259\n","Epoch 78/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5020 - accuracy: 0.4187 - val_loss: 6.6850 - val_accuracy: 0.2567\n","Epoch 79/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5022 - accuracy: 0.4223 - val_loss: 3.7566 - val_accuracy: 0.3302\n","Epoch 80/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5125 - accuracy: 0.4242 - val_loss: 1.4609 - val_accuracy: 0.4335\n","Epoch 81/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.5041 - accuracy: 0.4220 - val_loss: 6.5451 - val_accuracy: 0.2398\n","Epoch 82/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4967 - accuracy: 0.4224 - val_loss: 2.4798 - val_accuracy: 0.4008\n","Epoch 83/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5074 - accuracy: 0.4264 - val_loss: 2.4552 - val_accuracy: 0.3006\n","Epoch 84/150\n","215/215 [==============================] - 10s 48ms/step - loss: 1.5028 - accuracy: 0.4263 - val_loss: 2.7117 - val_accuracy: 0.3713\n","Epoch 85/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.5035 - accuracy: 0.4211 - val_loss: 2.6969 - val_accuracy: 0.3031\n","Epoch 86/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.5049 - accuracy: 0.4264 - val_loss: 2.0585 - val_accuracy: 0.3555\n","Epoch 87/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.4965 - accuracy: 0.4287 - val_loss: 2.9835 - val_accuracy: 0.3499\n","Epoch 88/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.5056 - accuracy: 0.4261 - val_loss: 1.7578 - val_accuracy: 0.4100\n","Epoch 89/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.4956 - accuracy: 0.4291 - val_loss: 2.3162 - val_accuracy: 0.3949\n","Epoch 90/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.4879 - accuracy: 0.4319 - val_loss: 1.5617 - val_accuracy: 0.4385\n","Epoch 91/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.4997 - accuracy: 0.4312 - val_loss: 3.0905 - val_accuracy: 0.3376\n","Epoch 92/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.4979 - accuracy: 0.4232 - val_loss: 2.1038 - val_accuracy: 0.3692\n","Epoch 93/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.4995 - accuracy: 0.4292 - val_loss: 11.4049 - val_accuracy: 0.2173\n","Epoch 94/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.4848 - accuracy: 0.4311 - val_loss: 5.0245 - val_accuracy: 0.2943\n","Epoch 95/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.4920 - accuracy: 0.4318 - val_loss: 1.8814 - val_accuracy: 0.4307\n","Epoch 96/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.4943 - accuracy: 0.4301 - val_loss: 5.5945 - val_accuracy: 0.2345\n","Epoch 97/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4913 - accuracy: 0.4264 - val_loss: 3.7597 - val_accuracy: 0.3949\n","Epoch 98/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4875 - accuracy: 0.4252 - val_loss: 3.0268 - val_accuracy: 0.3882\n","Epoch 99/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4807 - accuracy: 0.4373 - val_loss: 2.1244 - val_accuracy: 0.3892\n","Epoch 100/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.5027 - accuracy: 0.4259 - val_loss: 3.5724 - val_accuracy: 0.3038\n","Epoch 101/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4925 - accuracy: 0.4299 - val_loss: 1.3997 - val_accuracy: 0.4578\n","Epoch 102/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4970 - accuracy: 0.4279 - val_loss: 1.8600 - val_accuracy: 0.4030\n","Epoch 103/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4889 - accuracy: 0.4335 - val_loss: 4.8042 - val_accuracy: 0.3105\n","Epoch 104/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4861 - accuracy: 0.4314 - val_loss: 2.5156 - val_accuracy: 0.4023\n","Epoch 105/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.4991 - accuracy: 0.4304 - val_loss: 5.8373 - val_accuracy: 0.2862\n","Epoch 106/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.4831 - accuracy: 0.4310 - val_loss: 2.7917 - val_accuracy: 0.3463\n","Epoch 107/150\n","215/215 [==============================] - 12s 57ms/step - loss: 1.4896 - accuracy: 0.4248 - val_loss: 1.4937 - val_accuracy: 0.4560\n","Epoch 108/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.4812 - accuracy: 0.4332 - val_loss: 5.4809 - val_accuracy: 0.2620\n","Epoch 109/150\n","215/215 [==============================] - 12s 55ms/step - loss: 1.4906 - accuracy: 0.4280 - val_loss: 2.3951 - val_accuracy: 0.3052\n","Epoch 110/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.4847 - accuracy: 0.4380 - val_loss: 2.4893 - val_accuracy: 0.3973\n","Epoch 111/150\n","215/215 [==============================] - 12s 57ms/step - loss: 1.4891 - accuracy: 0.4324 - val_loss: 4.2266 - val_accuracy: 0.3537\n","Epoch 112/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4968 - accuracy: 0.4351 - val_loss: 5.5844 - val_accuracy: 0.2693\n","Epoch 113/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4942 - accuracy: 0.4324 - val_loss: 2.1742 - val_accuracy: 0.3797\n","Epoch 114/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4845 - accuracy: 0.4310 - val_loss: 1.6704 - val_accuracy: 0.3903\n","Epoch 115/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4772 - accuracy: 0.4330 - val_loss: 3.5585 - val_accuracy: 0.3432\n","Epoch 116/150\n","215/215 [==============================] - 13s 58ms/step - loss: 1.4997 - accuracy: 0.4256 - val_loss: 9.2723 - val_accuracy: 0.2764\n","Epoch 117/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4810 - accuracy: 0.4324 - val_loss: 2.8285 - val_accuracy: 0.3829\n","Epoch 118/150\n","215/215 [==============================] - 14s 64ms/step - loss: 1.4894 - accuracy: 0.4341 - val_loss: 1.4492 - val_accuracy: 0.4374\n","Epoch 119/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4964 - accuracy: 0.4290 - val_loss: 6.1956 - val_accuracy: 0.3372\n","Epoch 120/150\n","215/215 [==============================] - 13s 58ms/step - loss: 1.4954 - accuracy: 0.4348 - val_loss: 1.8162 - val_accuracy: 0.3442\n","Epoch 121/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4778 - accuracy: 0.4368 - val_loss: 3.3310 - val_accuracy: 0.3470\n","Epoch 122/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4807 - accuracy: 0.4420 - val_loss: 2.9473 - val_accuracy: 0.3643\n","Epoch 123/150\n","215/215 [==============================] - 13s 60ms/step - loss: 1.4844 - accuracy: 0.4357 - val_loss: 3.5729 - val_accuracy: 0.2669\n","Epoch 124/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4763 - accuracy: 0.4370 - val_loss: 2.5386 - val_accuracy: 0.3516\n","Epoch 125/150\n","215/215 [==============================] - 12s 57ms/step - loss: 1.4806 - accuracy: 0.4409 - val_loss: 3.8026 - val_accuracy: 0.3404\n","Epoch 126/150\n","215/215 [==============================] - 12s 58ms/step - loss: 1.4802 - accuracy: 0.4355 - val_loss: 2.8705 - val_accuracy: 0.3400\n","Epoch 127/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4863 - accuracy: 0.4379 - val_loss: 2.5703 - val_accuracy: 0.4015\n","Epoch 128/150\n","215/215 [==============================] - 14s 65ms/step - loss: 1.4829 - accuracy: 0.4359 - val_loss: 2.8970 - val_accuracy: 0.3959\n","Epoch 129/150\n","215/215 [==============================] - 13s 59ms/step - loss: 1.4792 - accuracy: 0.4355 - val_loss: 1.9537 - val_accuracy: 0.3695\n","Epoch 130/150\n","215/215 [==============================] - 12s 54ms/step - loss: 1.4793 - accuracy: 0.4394 - val_loss: 3.8215 - val_accuracy: 0.3129\n","Epoch 131/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.4884 - accuracy: 0.4366 - val_loss: 3.6847 - val_accuracy: 0.3748\n","Epoch 132/150\n","215/215 [==============================] - 11s 52ms/step - loss: 1.4811 - accuracy: 0.4331 - val_loss: 2.6433 - val_accuracy: 0.3523\n","Epoch 133/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4811 - accuracy: 0.4360 - val_loss: 3.2924 - val_accuracy: 0.3850\n","Epoch 134/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4822 - accuracy: 0.4409 - val_loss: 4.1737 - val_accuracy: 0.2757\n","Epoch 135/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4877 - accuracy: 0.4314 - val_loss: 1.5909 - val_accuracy: 0.4075\n","Epoch 136/150\n","215/215 [==============================] - 11s 53ms/step - loss: 1.4913 - accuracy: 0.4356 - val_loss: 5.4147 - val_accuracy: 0.3228\n","Epoch 137/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4928 - accuracy: 0.4305 - val_loss: 2.1166 - val_accuracy: 0.3625\n","Epoch 138/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4819 - accuracy: 0.4310 - val_loss: 2.5127 - val_accuracy: 0.3878\n","Epoch 139/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4736 - accuracy: 0.4404 - val_loss: 2.5168 - val_accuracy: 0.2788\n","Epoch 140/150\n","215/215 [==============================] - 12s 56ms/step - loss: 1.4740 - accuracy: 0.4429 - val_loss: 1.7233 - val_accuracy: 0.4146\n","Epoch 141/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4840 - accuracy: 0.4368 - val_loss: 2.2974 - val_accuracy: 0.3903\n","Epoch 142/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4759 - accuracy: 0.4430 - val_loss: 1.9017 - val_accuracy: 0.4015\n","Epoch 143/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4847 - accuracy: 0.4379 - val_loss: 2.5529 - val_accuracy: 0.3875\n","Epoch 144/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4832 - accuracy: 0.4401 - val_loss: 2.1522 - val_accuracy: 0.3731\n","Epoch 145/150\n","215/215 [==============================] - 11s 49ms/step - loss: 1.4873 - accuracy: 0.4363 - val_loss: 1.6622 - val_accuracy: 0.3822\n","Epoch 146/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4832 - accuracy: 0.4381 - val_loss: 2.5441 - val_accuracy: 0.3871\n","Epoch 147/150\n","215/215 [==============================] - 11s 50ms/step - loss: 1.4785 - accuracy: 0.4357 - val_loss: 2.9773 - val_accuracy: 0.3608\n","Epoch 148/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4861 - accuracy: 0.4299 - val_loss: 7.8504 - val_accuracy: 0.3013\n","Epoch 149/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4816 - accuracy: 0.4346 - val_loss: 4.2932 - val_accuracy: 0.2679\n","Epoch 150/150\n","215/215 [==============================] - 11s 51ms/step - loss: 1.4836 - accuracy: 0.4394 - val_loss: 2.4500 - val_accuracy: 0.3724\n"]}]},{"cell_type":"code","source":["# Guardar el Modelo\n","model_final.save('/content/drive/MyDrive/DeepMecProject/model2.h5')\n","model_final.save('/content/drive/MyDrive/DeepMecProject/model3', save_format='tf')\n","# Recrea exactamente el mismo modelo solo desde el archivo\n","#new_model = keras.models.load_model('/content/drive/MyDrive/DeepMecProject/model2.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XhhyomFBzSd","executionInfo":{"status":"ok","timestamp":1657815833792,"user_tz":240,"elapsed":2604,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"4ae79e06-5c02-420b-b2d8-c64386de5a66"},"execution_count":187,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/DeepMecProject/model3/assets\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","import seaborn as sns\n","import sklearn.metrics as metrics \n","\n","test_batch =[]\n","for data in next(test_data):\n","  test_batch.append(data)\n","\n","image_batch = test_batch[0]\n","label_batch= test_batch[1]\n","\n","loss, accuracy = model_final.evaluate(image_batch, label_batch)\n","predictions= tf.argmax(model_final.predict(image_batch),axis=1)\n","label_batch = tf.argmax(label_batch, axis=1)\n","cf_matrix = tf.math.confusion_matrix(label_batch, predictions)\n","sns.set(rc = {'figure.figsize':(15,8)})\n","sns.heatmap(cf_matrix, annot=True)\n","f1_score = metrics.classification_report(label_batch, predictions)\n","print(f1_score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":787},"id":"JZ-U1_in4DoX","executionInfo":{"status":"ok","timestamp":1657815424699,"user_tz":240,"elapsed":2419,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"8789ab58-b9cd-453f-c88d-f3240e2bb0bb"},"execution_count":184,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 47ms/step - loss: 2.3657 - accuracy: 0.3871\n","WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f41ec27ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","              precision    recall  f1-score   support\n","\n","           0       0.30      0.43      0.35         7\n","           1       1.00      0.40      0.57         5\n","           2       0.14      0.17      0.15         6\n","           3       0.54      0.54      0.54        13\n","           4       0.50      0.08      0.14        12\n","           5       0.50      0.12      0.20         8\n","           6       0.35      0.82      0.49        11\n","\n","    accuracy                           0.39        62\n","   macro avg       0.48      0.37      0.35        62\n","weighted avg       0.46      0.39      0.35        62\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x576 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["new_model = tf.keras.models.load_model('/content/drive/MyDrive/DeepMecProject/model2.h5')"],"metadata":{"id":"7lm7D46JgIkX","executionInfo":{"status":"ok","timestamp":1657815577346,"user_tz":240,"elapsed":930,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":186,"outputs":[]},{"cell_type":"code","source":["loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/DeepMecProject/model3')"],"metadata":{"id":"BfPYHUd9gj6l","executionInfo":{"status":"ok","timestamp":1657816492265,"user_tz":240,"elapsed":1359,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":190,"outputs":[]},{"cell_type":"code","source":["#cargamos el modelo efficientNet de keras\n","from tensorflow.keras.applications import MobileNetV3Small\n","img_input = tf.keras.layers.Input(shape=(48, 48,1))\n","img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])  \n","\n","base_model2 = MobileNetV3Small(include_top = False, weights = None,input_tensor=img_conc, classes=7)#classes=7"],"metadata":{"id":"AB4wM4BSl1xF","executionInfo":{"status":"ok","timestamp":1657818259397,"user_tz":240,"elapsed":2081,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":197,"outputs":[]},{"cell_type":"code","source":["base_model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maiWwZqApw6a","executionInfo":{"status":"ok","timestamp":1657818466794,"user_tz":240,"elapsed":2634,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"a946b523-b2bf-4afb-8072-eafc978eb277"},"execution_count":202,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"MobilenetV3small\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_28 (InputLayer)          [(None, 48, 48, 1)]  0           []                               \n","                                                                                                  \n"," concatenate_27 (Concatenate)   (None, 48, 48, 3)    0           ['input_28[0][0]',               \n","                                                                  'input_28[0][0]',               \n","                                                                  'input_28[0][0]']               \n","                                                                                                  \n"," rescaling_2 (Rescaling)        (None, 48, 48, 3)    0           ['concatenate_27[0][0]']         \n","                                                                                                  \n"," Conv (Conv2D)                  (None, 24, 24, 16)   432         ['rescaling_2[0][0]']            \n","                                                                                                  \n"," Conv/BatchNorm (BatchNormaliza  (None, 24, 24, 16)  64          ['Conv[0][0]']                   \n"," tion)                                                                                            \n","                                                                                                  \n"," tf.__operators__.add_54 (TFOpL  (None, 24, 24, 16)  0           ['Conv/BatchNorm[0][0]']         \n"," ambda)                                                                                           \n","                                                                                                  \n"," re_lu_64 (ReLU)                (None, 24, 24, 16)   0           ['tf.__operators__.add_54[0][0]']\n","                                                                                                  \n"," tf.math.multiply_54 (TFOpLambd  (None, 24, 24, 16)  0           ['re_lu_64[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_36 (Multiply)         (None, 24, 24, 16)   0           ['Conv/BatchNorm[0][0]',         \n","                                                                  'tf.math.multiply_54[0][0]']    \n","                                                                                                  \n"," expanded_conv/depthwise/pad (Z  (None, 25, 25, 16)  0           ['multiply_36[0][0]']            \n"," eroPadding2D)                                                                                    \n","                                                                                                  \n"," expanded_conv/depthwise (Depth  (None, 12, 12, 16)  144         ['expanded_conv/depthwise/pad[0][\n"," wiseConv2D)                                                     0]']                             \n","                                                                                                  \n"," expanded_conv/depthwise/BatchN  (None, 12, 12, 16)  64          ['expanded_conv/depthwise[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," re_lu_65 (ReLU)                (None, 12, 12, 16)   0           ['expanded_conv/depthwise/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv/squeeze_excite/A  (None, 1, 1, 16)    0           ['re_lu_65[0][0]']               \n"," vgPool (GlobalAveragePooling2D                                                                   \n"," )                                                                                                \n","                                                                                                  \n"," expanded_conv/squeeze_excite/C  (None, 1, 1, 8)     136         ['expanded_conv/squeeze_excite/Av\n"," onv (Conv2D)                                                    gPool[0][0]']                    \n","                                                                                                  \n"," expanded_conv/squeeze_excite/R  (None, 1, 1, 8)     0           ['expanded_conv/squeeze_excite/Co\n"," elu (ReLU)                                                      nv[0][0]']                       \n","                                                                                                  \n"," expanded_conv/squeeze_excite/C  (None, 1, 1, 16)    144         ['expanded_conv/squeeze_excite/Re\n"," onv_1 (Conv2D)                                                  lu[0][0]']                       \n","                                                                                                  \n"," tf.__operators__.add_55 (TFOpL  (None, 1, 1, 16)    0           ['expanded_conv/squeeze_excite/Co\n"," ambda)                                                          nv_1[0][0]']                     \n","                                                                                                  \n"," re_lu_66 (ReLU)                (None, 1, 1, 16)     0           ['tf.__operators__.add_55[0][0]']\n","                                                                                                  \n"," tf.math.multiply_55 (TFOpLambd  (None, 1, 1, 16)    0           ['re_lu_66[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv/squeeze_excite/M  (None, 12, 12, 16)  0           ['re_lu_65[0][0]',               \n"," ul (Multiply)                                                    'tf.math.multiply_55[0][0]']    \n","                                                                                                  \n"," expanded_conv/project (Conv2D)  (None, 12, 12, 16)  256         ['expanded_conv/squeeze_excite/Mu\n","                                                                 l[0][0]']                        \n","                                                                                                  \n"," expanded_conv/project/BatchNor  (None, 12, 12, 16)  64          ['expanded_conv/project[0][0]']  \n"," m (BatchNormalization)                                                                           \n","                                                                                                  \n"," expanded_conv_1/expand (Conv2D  (None, 12, 12, 72)  1152        ['expanded_conv/project/BatchNorm\n"," )                                                               [0][0]']                         \n","                                                                                                  \n"," expanded_conv_1/expand/BatchNo  (None, 12, 12, 72)  288         ['expanded_conv_1/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," re_lu_67 (ReLU)                (None, 12, 12, 72)   0           ['expanded_conv_1/expand/BatchNor\n","                                                                 m[0][0]']                        \n","                                                                                                  \n"," expanded_conv_1/depthwise/pad   (None, 13, 13, 72)  0           ['re_lu_67[0][0]']               \n"," (ZeroPadding2D)                                                                                  \n","                                                                                                  \n"," expanded_conv_1/depthwise (Dep  (None, 6, 6, 72)    648         ['expanded_conv_1/depthwise/pad[0\n"," thwiseConv2D)                                                   ][0]']                           \n","                                                                                                  \n"," expanded_conv_1/depthwise/Batc  (None, 6, 6, 72)    288         ['expanded_conv_1/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," re_lu_68 (ReLU)                (None, 6, 6, 72)     0           ['expanded_conv_1/depthwise/Batch\n","                                                                 Norm[0][0]']                     \n","                                                                                                  \n"," expanded_conv_1/project (Conv2  (None, 6, 6, 24)    1728        ['re_lu_68[0][0]']               \n"," D)                                                                                               \n","                                                                                                  \n"," expanded_conv_1/project/BatchN  (None, 6, 6, 24)    96          ['expanded_conv_1/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_2/expand (Conv2D  (None, 6, 6, 88)    2112        ['expanded_conv_1/project/BatchNo\n"," )                                                               rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_2/expand/BatchNo  (None, 6, 6, 88)    352         ['expanded_conv_2/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," re_lu_69 (ReLU)                (None, 6, 6, 88)     0           ['expanded_conv_2/expand/BatchNor\n","                                                                 m[0][0]']                        \n","                                                                                                  \n"," expanded_conv_2/depthwise (Dep  (None, 6, 6, 88)    792         ['re_lu_69[0][0]']               \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_2/depthwise/Batc  (None, 6, 6, 88)    352         ['expanded_conv_2/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," re_lu_70 (ReLU)                (None, 6, 6, 88)     0           ['expanded_conv_2/depthwise/Batch\n","                                                                 Norm[0][0]']                     \n","                                                                                                  \n"," expanded_conv_2/project (Conv2  (None, 6, 6, 24)    2112        ['re_lu_70[0][0]']               \n"," D)                                                                                               \n","                                                                                                  \n"," expanded_conv_2/project/BatchN  (None, 6, 6, 24)    96          ['expanded_conv_2/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_2/Add (Add)      (None, 6, 6, 24)     0           ['expanded_conv_1/project/BatchNo\n","                                                                 rm[0][0]',                       \n","                                                                  'expanded_conv_2/project/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_3/expand (Conv2D  (None, 6, 6, 96)    2304        ['expanded_conv_2/Add[0][0]']    \n"," )                                                                                                \n","                                                                                                  \n"," expanded_conv_3/expand/BatchNo  (None, 6, 6, 96)    384         ['expanded_conv_3/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_56 (TFOpL  (None, 6, 6, 96)    0           ['expanded_conv_3/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_71 (ReLU)                (None, 6, 6, 96)     0           ['tf.__operators__.add_56[0][0]']\n","                                                                                                  \n"," tf.math.multiply_56 (TFOpLambd  (None, 6, 6, 96)    0           ['re_lu_71[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_37 (Multiply)         (None, 6, 6, 96)     0           ['expanded_conv_3/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_56[0][0]']    \n","                                                                                                  \n"," expanded_conv_3/depthwise/pad   (None, 9, 9, 96)    0           ['multiply_37[0][0]']            \n"," (ZeroPadding2D)                                                                                  \n","                                                                                                  \n"," expanded_conv_3/depthwise (Dep  (None, 3, 3, 96)    2400        ['expanded_conv_3/depthwise/pad[0\n"," thwiseConv2D)                                                   ][0]']                           \n","                                                                                                  \n"," expanded_conv_3/depthwise/Batc  (None, 3, 3, 96)    384         ['expanded_conv_3/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_57 (TFOpL  (None, 3, 3, 96)    0           ['expanded_conv_3/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_72 (ReLU)                (None, 3, 3, 96)     0           ['tf.__operators__.add_57[0][0]']\n","                                                                                                  \n"," tf.math.multiply_57 (TFOpLambd  (None, 3, 3, 96)    0           ['re_lu_72[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_38 (Multiply)         (None, 3, 3, 96)     0           ['expanded_conv_3/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_57[0][0]']    \n","                                                                                                  \n"," expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    0           ['multiply_38[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    2328        ['expanded_conv_3/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_3/squeeze_excite  (None, 1, 1, 24)    0           ['expanded_conv_3/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_3/squeeze_excite  (None, 1, 1, 96)    2400        ['expanded_conv_3/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_58 (TFOpL  (None, 1, 1, 96)    0           ['expanded_conv_3/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_73 (ReLU)                (None, 1, 1, 96)     0           ['tf.__operators__.add_58[0][0]']\n","                                                                                                  \n"," tf.math.multiply_58 (TFOpLambd  (None, 1, 1, 96)    0           ['re_lu_73[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_3/squeeze_excite  (None, 3, 3, 96)    0           ['multiply_38[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_58[0][0]']    \n","                                                                                                  \n"," expanded_conv_3/project (Conv2  (None, 3, 3, 40)    3840        ['expanded_conv_3/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_3/project/BatchN  (None, 3, 3, 40)    160         ['expanded_conv_3/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_4/expand (Conv2D  (None, 3, 3, 240)   9600        ['expanded_conv_3/project/BatchNo\n"," )                                                               rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_4/expand/BatchNo  (None, 3, 3, 240)   960         ['expanded_conv_4/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_59 (TFOpL  (None, 3, 3, 240)   0           ['expanded_conv_4/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_74 (ReLU)                (None, 3, 3, 240)    0           ['tf.__operators__.add_59[0][0]']\n","                                                                                                  \n"," tf.math.multiply_59 (TFOpLambd  (None, 3, 3, 240)   0           ['re_lu_74[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_39 (Multiply)         (None, 3, 3, 240)    0           ['expanded_conv_4/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_59[0][0]']    \n","                                                                                                  \n"," expanded_conv_4/depthwise (Dep  (None, 3, 3, 240)   6000        ['multiply_39[0][0]']            \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_4/depthwise/Batc  (None, 3, 3, 240)   960         ['expanded_conv_4/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_60 (TFOpL  (None, 3, 3, 240)   0           ['expanded_conv_4/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_75 (ReLU)                (None, 3, 3, 240)    0           ['tf.__operators__.add_60[0][0]']\n","                                                                                                  \n"," tf.math.multiply_60 (TFOpLambd  (None, 3, 3, 240)   0           ['re_lu_75[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_40 (Multiply)         (None, 3, 3, 240)    0           ['expanded_conv_4/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_60[0][0]']    \n","                                                                                                  \n"," expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_40[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_4/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_4/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_4/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_4/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_4/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_61 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_4/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_76 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_61[0][0]']\n","                                                                                                  \n"," tf.math.multiply_61 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_76[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_4/squeeze_excite  (None, 3, 3, 240)   0           ['multiply_40[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_61[0][0]']    \n","                                                                                                  \n"," expanded_conv_4/project (Conv2  (None, 3, 3, 40)    9600        ['expanded_conv_4/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_4/project/BatchN  (None, 3, 3, 40)    160         ['expanded_conv_4/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_4/Add (Add)      (None, 3, 3, 40)     0           ['expanded_conv_3/project/BatchNo\n","                                                                 rm[0][0]',                       \n","                                                                  'expanded_conv_4/project/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_5/expand (Conv2D  (None, 3, 3, 240)   9600        ['expanded_conv_4/Add[0][0]']    \n"," )                                                                                                \n","                                                                                                  \n"," expanded_conv_5/expand/BatchNo  (None, 3, 3, 240)   960         ['expanded_conv_5/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_62 (TFOpL  (None, 3, 3, 240)   0           ['expanded_conv_5/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_77 (ReLU)                (None, 3, 3, 240)    0           ['tf.__operators__.add_62[0][0]']\n","                                                                                                  \n"," tf.math.multiply_62 (TFOpLambd  (None, 3, 3, 240)   0           ['re_lu_77[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_41 (Multiply)         (None, 3, 3, 240)    0           ['expanded_conv_5/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_62[0][0]']    \n","                                                                                                  \n"," expanded_conv_5/depthwise (Dep  (None, 3, 3, 240)   6000        ['multiply_41[0][0]']            \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_5/depthwise/Batc  (None, 3, 3, 240)   960         ['expanded_conv_5/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_63 (TFOpL  (None, 3, 3, 240)   0           ['expanded_conv_5/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_78 (ReLU)                (None, 3, 3, 240)    0           ['tf.__operators__.add_63[0][0]']\n","                                                                                                  \n"," tf.math.multiply_63 (TFOpLambd  (None, 3, 3, 240)   0           ['re_lu_78[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_42 (Multiply)         (None, 3, 3, 240)    0           ['expanded_conv_5/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_63[0][0]']    \n","                                                                                                  \n"," expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   0           ['multiply_42[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    15424       ['expanded_conv_5/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_5/squeeze_excite  (None, 1, 1, 64)    0           ['expanded_conv_5/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_5/squeeze_excite  (None, 1, 1, 240)   15600       ['expanded_conv_5/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_64 (TFOpL  (None, 1, 1, 240)   0           ['expanded_conv_5/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_79 (ReLU)                (None, 1, 1, 240)    0           ['tf.__operators__.add_64[0][0]']\n","                                                                                                  \n"," tf.math.multiply_64 (TFOpLambd  (None, 1, 1, 240)   0           ['re_lu_79[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_5/squeeze_excite  (None, 3, 3, 240)   0           ['multiply_42[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_64[0][0]']    \n","                                                                                                  \n"," expanded_conv_5/project (Conv2  (None, 3, 3, 40)    9600        ['expanded_conv_5/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_5/project/BatchN  (None, 3, 3, 40)    160         ['expanded_conv_5/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_5/Add (Add)      (None, 3, 3, 40)     0           ['expanded_conv_4/Add[0][0]',    \n","                                                                  'expanded_conv_5/project/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_6/expand (Conv2D  (None, 3, 3, 120)   4800        ['expanded_conv_5/Add[0][0]']    \n"," )                                                                                                \n","                                                                                                  \n"," expanded_conv_6/expand/BatchNo  (None, 3, 3, 120)   480         ['expanded_conv_6/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_65 (TFOpL  (None, 3, 3, 120)   0           ['expanded_conv_6/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_80 (ReLU)                (None, 3, 3, 120)    0           ['tf.__operators__.add_65[0][0]']\n","                                                                                                  \n"," tf.math.multiply_65 (TFOpLambd  (None, 3, 3, 120)   0           ['re_lu_80[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_43 (Multiply)         (None, 3, 3, 120)    0           ['expanded_conv_6/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_65[0][0]']    \n","                                                                                                  \n"," expanded_conv_6/depthwise (Dep  (None, 3, 3, 120)   3000        ['multiply_43[0][0]']            \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_6/depthwise/Batc  (None, 3, 3, 120)   480         ['expanded_conv_6/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_66 (TFOpL  (None, 3, 3, 120)   0           ['expanded_conv_6/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_81 (ReLU)                (None, 3, 3, 120)    0           ['tf.__operators__.add_66[0][0]']\n","                                                                                                  \n"," tf.math.multiply_66 (TFOpLambd  (None, 3, 3, 120)   0           ['re_lu_81[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_44 (Multiply)         (None, 3, 3, 120)    0           ['expanded_conv_6/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_66[0][0]']    \n","                                                                                                  \n"," expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   0           ['multiply_44[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    3872        ['expanded_conv_6/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_6/squeeze_excite  (None, 1, 1, 32)    0           ['expanded_conv_6/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_6/squeeze_excite  (None, 1, 1, 120)   3960        ['expanded_conv_6/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_67 (TFOpL  (None, 1, 1, 120)   0           ['expanded_conv_6/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_82 (ReLU)                (None, 1, 1, 120)    0           ['tf.__operators__.add_67[0][0]']\n","                                                                                                  \n"," tf.math.multiply_67 (TFOpLambd  (None, 1, 1, 120)   0           ['re_lu_82[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_6/squeeze_excite  (None, 3, 3, 120)   0           ['multiply_44[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_67[0][0]']    \n","                                                                                                  \n"," expanded_conv_6/project (Conv2  (None, 3, 3, 48)    5760        ['expanded_conv_6/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_6/project/BatchN  (None, 3, 3, 48)    192         ['expanded_conv_6/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_7/expand (Conv2D  (None, 3, 3, 144)   6912        ['expanded_conv_6/project/BatchNo\n"," )                                                               rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_7/expand/BatchNo  (None, 3, 3, 144)   576         ['expanded_conv_7/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_68 (TFOpL  (None, 3, 3, 144)   0           ['expanded_conv_7/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_83 (ReLU)                (None, 3, 3, 144)    0           ['tf.__operators__.add_68[0][0]']\n","                                                                                                  \n"," tf.math.multiply_68 (TFOpLambd  (None, 3, 3, 144)   0           ['re_lu_83[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_45 (Multiply)         (None, 3, 3, 144)    0           ['expanded_conv_7/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_68[0][0]']    \n","                                                                                                  \n"," expanded_conv_7/depthwise (Dep  (None, 3, 3, 144)   3600        ['multiply_45[0][0]']            \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_7/depthwise/Batc  (None, 3, 3, 144)   576         ['expanded_conv_7/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_69 (TFOpL  (None, 3, 3, 144)   0           ['expanded_conv_7/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_84 (ReLU)                (None, 3, 3, 144)    0           ['tf.__operators__.add_69[0][0]']\n","                                                                                                  \n"," tf.math.multiply_69 (TFOpLambd  (None, 3, 3, 144)   0           ['re_lu_84[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_46 (Multiply)         (None, 3, 3, 144)    0           ['expanded_conv_7/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_69[0][0]']    \n","                                                                                                  \n"," expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   0           ['multiply_46[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    5800        ['expanded_conv_7/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_7/squeeze_excite  (None, 1, 1, 40)    0           ['expanded_conv_7/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_7/squeeze_excite  (None, 1, 1, 144)   5904        ['expanded_conv_7/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_70 (TFOpL  (None, 1, 1, 144)   0           ['expanded_conv_7/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_85 (ReLU)                (None, 1, 1, 144)    0           ['tf.__operators__.add_70[0][0]']\n","                                                                                                  \n"," tf.math.multiply_70 (TFOpLambd  (None, 1, 1, 144)   0           ['re_lu_85[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_7/squeeze_excite  (None, 3, 3, 144)   0           ['multiply_46[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_70[0][0]']    \n","                                                                                                  \n"," expanded_conv_7/project (Conv2  (None, 3, 3, 48)    6912        ['expanded_conv_7/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_7/project/BatchN  (None, 3, 3, 48)    192         ['expanded_conv_7/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_7/Add (Add)      (None, 3, 3, 48)     0           ['expanded_conv_6/project/BatchNo\n","                                                                 rm[0][0]',                       \n","                                                                  'expanded_conv_7/project/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_8/expand (Conv2D  (None, 3, 3, 288)   13824       ['expanded_conv_7/Add[0][0]']    \n"," )                                                                                                \n","                                                                                                  \n"," expanded_conv_8/expand/BatchNo  (None, 3, 3, 288)   1152        ['expanded_conv_8/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_71 (TFOpL  (None, 3, 3, 288)   0           ['expanded_conv_8/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_86 (ReLU)                (None, 3, 3, 288)    0           ['tf.__operators__.add_71[0][0]']\n","                                                                                                  \n"," tf.math.multiply_71 (TFOpLambd  (None, 3, 3, 288)   0           ['re_lu_86[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_47 (Multiply)         (None, 3, 3, 288)    0           ['expanded_conv_8/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_71[0][0]']    \n","                                                                                                  \n"," expanded_conv_8/depthwise/pad   (None, 7, 7, 288)   0           ['multiply_47[0][0]']            \n"," (ZeroPadding2D)                                                                                  \n","                                                                                                  \n"," expanded_conv_8/depthwise (Dep  (None, 2, 2, 288)   7200        ['expanded_conv_8/depthwise/pad[0\n"," thwiseConv2D)                                                   ][0]']                           \n","                                                                                                  \n"," expanded_conv_8/depthwise/Batc  (None, 2, 2, 288)   1152        ['expanded_conv_8/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_72 (TFOpL  (None, 2, 2, 288)   0           ['expanded_conv_8/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_87 (ReLU)                (None, 2, 2, 288)    0           ['tf.__operators__.add_72[0][0]']\n","                                                                                                  \n"," tf.math.multiply_72 (TFOpLambd  (None, 2, 2, 288)   0           ['re_lu_87[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_48 (Multiply)         (None, 2, 2, 288)    0           ['expanded_conv_8/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_72[0][0]']    \n","                                                                                                  \n"," expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   0           ['multiply_48[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    20808       ['expanded_conv_8/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_8/squeeze_excite  (None, 1, 1, 72)    0           ['expanded_conv_8/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_8/squeeze_excite  (None, 1, 1, 288)   21024       ['expanded_conv_8/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_73 (TFOpL  (None, 1, 1, 288)   0           ['expanded_conv_8/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_88 (ReLU)                (None, 1, 1, 288)    0           ['tf.__operators__.add_73[0][0]']\n","                                                                                                  \n"," tf.math.multiply_73 (TFOpLambd  (None, 1, 1, 288)   0           ['re_lu_88[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_8/squeeze_excite  (None, 2, 2, 288)   0           ['multiply_48[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_73[0][0]']    \n","                                                                                                  \n"," expanded_conv_8/project (Conv2  (None, 2, 2, 96)    27648       ['expanded_conv_8/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_8/project/BatchN  (None, 2, 2, 96)    384         ['expanded_conv_8/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_9/expand (Conv2D  (None, 2, 2, 576)   55296       ['expanded_conv_8/project/BatchNo\n"," )                                                               rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_9/expand/BatchNo  (None, 2, 2, 576)   2304        ['expanded_conv_9/expand[0][0]'] \n"," rm (BatchNormalization)                                                                          \n","                                                                                                  \n"," tf.__operators__.add_74 (TFOpL  (None, 2, 2, 576)   0           ['expanded_conv_9/expand/BatchNor\n"," ambda)                                                          m[0][0]']                        \n","                                                                                                  \n"," re_lu_89 (ReLU)                (None, 2, 2, 576)    0           ['tf.__operators__.add_74[0][0]']\n","                                                                                                  \n"," tf.math.multiply_74 (TFOpLambd  (None, 2, 2, 576)   0           ['re_lu_89[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_49 (Multiply)         (None, 2, 2, 576)    0           ['expanded_conv_9/expand/BatchNor\n","                                                                 m[0][0]',                        \n","                                                                  'tf.math.multiply_74[0][0]']    \n","                                                                                                  \n"," expanded_conv_9/depthwise (Dep  (None, 2, 2, 576)   14400       ['multiply_49[0][0]']            \n"," thwiseConv2D)                                                                                    \n","                                                                                                  \n"," expanded_conv_9/depthwise/Batc  (None, 2, 2, 576)   2304        ['expanded_conv_9/depthwise[0][0]\n"," hNorm (BatchNormalization)                                      ']                               \n","                                                                                                  \n"," tf.__operators__.add_75 (TFOpL  (None, 2, 2, 576)   0           ['expanded_conv_9/depthwise/Batch\n"," ambda)                                                          Norm[0][0]']                     \n","                                                                                                  \n"," re_lu_90 (ReLU)                (None, 2, 2, 576)    0           ['tf.__operators__.add_75[0][0]']\n","                                                                                                  \n"," tf.math.multiply_75 (TFOpLambd  (None, 2, 2, 576)   0           ['re_lu_90[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_50 (Multiply)         (None, 2, 2, 576)    0           ['expanded_conv_9/depthwise/Batch\n","                                                                 Norm[0][0]',                     \n","                                                                  'tf.math.multiply_75[0][0]']    \n","                                                                                                  \n"," expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   0           ['multiply_50[0][0]']            \n"," /AvgPool (GlobalAveragePooling                                                                   \n"," 2D)                                                                                              \n","                                                                                                  \n"," expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   83088       ['expanded_conv_9/squeeze_excite/\n"," /Conv (Conv2D)                                                  AvgPool[0][0]']                  \n","                                                                                                  \n"," expanded_conv_9/squeeze_excite  (None, 1, 1, 144)   0           ['expanded_conv_9/squeeze_excite/\n"," /Relu (ReLU)                                                    Conv[0][0]']                     \n","                                                                                                  \n"," expanded_conv_9/squeeze_excite  (None, 1, 1, 576)   83520       ['expanded_conv_9/squeeze_excite/\n"," /Conv_1 (Conv2D)                                                Relu[0][0]']                     \n","                                                                                                  \n"," tf.__operators__.add_76 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_9/squeeze_excite/\n"," ambda)                                                          Conv_1[0][0]']                   \n","                                                                                                  \n"," re_lu_91 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_76[0][0]']\n","                                                                                                  \n"," tf.math.multiply_76 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_91[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_9/squeeze_excite  (None, 2, 2, 576)   0           ['multiply_50[0][0]',            \n"," /Mul (Multiply)                                                  'tf.math.multiply_76[0][0]']    \n","                                                                                                  \n"," expanded_conv_9/project (Conv2  (None, 2, 2, 96)    55296       ['expanded_conv_9/squeeze_excite/\n"," D)                                                              Mul[0][0]']                      \n","                                                                                                  \n"," expanded_conv_9/project/BatchN  (None, 2, 2, 96)    384         ['expanded_conv_9/project[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," expanded_conv_9/Add (Add)      (None, 2, 2, 96)     0           ['expanded_conv_8/project/BatchNo\n","                                                                 rm[0][0]',                       \n","                                                                  'expanded_conv_9/project/BatchNo\n","                                                                 rm[0][0]']                       \n","                                                                                                  \n"," expanded_conv_10/expand (Conv2  (None, 2, 2, 576)   55296       ['expanded_conv_9/Add[0][0]']    \n"," D)                                                                                               \n","                                                                                                  \n"," expanded_conv_10/expand/BatchN  (None, 2, 2, 576)   2304        ['expanded_conv_10/expand[0][0]']\n"," orm (BatchNormalization)                                                                         \n","                                                                                                  \n"," tf.__operators__.add_77 (TFOpL  (None, 2, 2, 576)   0           ['expanded_conv_10/expand/BatchNo\n"," ambda)                                                          rm[0][0]']                       \n","                                                                                                  \n"," re_lu_92 (ReLU)                (None, 2, 2, 576)    0           ['tf.__operators__.add_77[0][0]']\n","                                                                                                  \n"," tf.math.multiply_77 (TFOpLambd  (None, 2, 2, 576)   0           ['re_lu_92[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_51 (Multiply)         (None, 2, 2, 576)    0           ['expanded_conv_10/expand/BatchNo\n","                                                                 rm[0][0]',                       \n","                                                                  'tf.math.multiply_77[0][0]']    \n","                                                                                                  \n"," expanded_conv_10/depthwise (De  (None, 2, 2, 576)   14400       ['multiply_51[0][0]']            \n"," pthwiseConv2D)                                                                                   \n","                                                                                                  \n"," expanded_conv_10/depthwise/Bat  (None, 2, 2, 576)   2304        ['expanded_conv_10/depthwise[0][0\n"," chNorm (BatchNormalization)                                     ]']                              \n","                                                                                                  \n"," tf.__operators__.add_78 (TFOpL  (None, 2, 2, 576)   0           ['expanded_conv_10/depthwise/Batc\n"," ambda)                                                          hNorm[0][0]']                    \n","                                                                                                  \n"," re_lu_93 (ReLU)                (None, 2, 2, 576)    0           ['tf.__operators__.add_78[0][0]']\n","                                                                                                  \n"," tf.math.multiply_78 (TFOpLambd  (None, 2, 2, 576)   0           ['re_lu_93[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_52 (Multiply)         (None, 2, 2, 576)    0           ['expanded_conv_10/depthwise/Batc\n","                                                                 hNorm[0][0]',                    \n","                                                                  'tf.math.multiply_78[0][0]']    \n","                                                                                                  \n"," expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   0           ['multiply_52[0][0]']            \n"," e/AvgPool (GlobalAveragePoolin                                                                   \n"," g2D)                                                                                             \n","                                                                                                  \n"," expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   83088       ['expanded_conv_10/squeeze_excite\n"," e/Conv (Conv2D)                                                 /AvgPool[0][0]']                 \n","                                                                                                  \n"," expanded_conv_10/squeeze_excit  (None, 1, 1, 144)   0           ['expanded_conv_10/squeeze_excite\n"," e/Relu (ReLU)                                                   /Conv[0][0]']                    \n","                                                                                                  \n"," expanded_conv_10/squeeze_excit  (None, 1, 1, 576)   83520       ['expanded_conv_10/squeeze_excite\n"," e/Conv_1 (Conv2D)                                               /Relu[0][0]']                    \n","                                                                                                  \n"," tf.__operators__.add_79 (TFOpL  (None, 1, 1, 576)   0           ['expanded_conv_10/squeeze_excite\n"," ambda)                                                          /Conv_1[0][0]']                  \n","                                                                                                  \n"," re_lu_94 (ReLU)                (None, 1, 1, 576)    0           ['tf.__operators__.add_79[0][0]']\n","                                                                                                  \n"," tf.math.multiply_79 (TFOpLambd  (None, 1, 1, 576)   0           ['re_lu_94[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," expanded_conv_10/squeeze_excit  (None, 2, 2, 576)   0           ['multiply_52[0][0]',            \n"," e/Mul (Multiply)                                                 'tf.math.multiply_79[0][0]']    \n","                                                                                                  \n"," expanded_conv_10/project (Conv  (None, 2, 2, 96)    55296       ['expanded_conv_10/squeeze_excite\n"," 2D)                                                             /Mul[0][0]']                     \n","                                                                                                  \n"," expanded_conv_10/project/Batch  (None, 2, 2, 96)    384         ['expanded_conv_10/project[0][0]'\n"," Norm (BatchNormalization)                                       ]                                \n","                                                                                                  \n"," expanded_conv_10/Add (Add)     (None, 2, 2, 96)     0           ['expanded_conv_9/Add[0][0]',    \n","                                                                  'expanded_conv_10/project/BatchN\n","                                                                 orm[0][0]']                      \n","                                                                                                  \n"," Conv_1 (Conv2D)                (None, 2, 2, 576)    55296       ['expanded_conv_10/Add[0][0]']   \n","                                                                                                  \n"," Conv_1/BatchNorm (BatchNormali  (None, 2, 2, 576)   2304        ['Conv_1[0][0]']                 \n"," zation)                                                                                          \n","                                                                                                  \n"," tf.__operators__.add_80 (TFOpL  (None, 2, 2, 576)   0           ['Conv_1/BatchNorm[0][0]']       \n"," ambda)                                                                                           \n","                                                                                                  \n"," re_lu_95 (ReLU)                (None, 2, 2, 576)    0           ['tf.__operators__.add_80[0][0]']\n","                                                                                                  \n"," tf.math.multiply_80 (TFOpLambd  (None, 2, 2, 576)   0           ['re_lu_95[0][0]']               \n"," a)                                                                                               \n","                                                                                                  \n"," multiply_53 (Multiply)         (None, 2, 2, 576)    0           ['Conv_1/BatchNorm[0][0]',       \n","                                                                  'tf.math.multiply_80[0][0]']    \n","                                                                                                  \n","==================================================================================================\n","Total params: 939,120\n","Trainable params: 927,008\n","Non-trainable params: 12,112\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["last_layers=base_model2.get_layer('re_lu_94')\n","last_output=last_layers.output"],"metadata":{"id":"DvQIAsjsrUMO","executionInfo":{"status":"ok","timestamp":1657818473745,"user_tz":240,"elapsed":2,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":203,"outputs":[]},{"cell_type":"code","source":["#x = tf.keras.layers.Dense(576, activation=\"relu\")(ba)\n","x = tf.keras.layers.Flatten()(last_output)\n","\n","x = tf.keras.layers.Dropout(0.5)(x)#(last_output)\n","#x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n","#x = tf.keras.layers.Flatten()(x)\n","\n","# Add a final sigmoid layer with 1 node for classification output\n","predictions = tf.keras.layers.Dense(7, activation=\"softmax\")(x)\n","model_final = Model(base_model2.input, predictions)"],"metadata":{"id":"XjBP_523mJvn","executionInfo":{"status":"ok","timestamp":1657818502115,"user_tz":240,"elapsed":464,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":205,"outputs":[]},{"cell_type":"code","source":["model_final.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.002),loss='categorical_crossentropy',metrics=['accuracy'])               "],"metadata":{"id":"3Fa3-dtsr0fS","executionInfo":{"status":"ok","timestamp":1657818537241,"user_tz":240,"elapsed":341,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}}},"execution_count":206,"outputs":[]},{"cell_type":"code","source":["mn2_history = model_final.fit(train_data,validation_data = valid_data, epochs = 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8G9VGNrLr2Ib","executionInfo":{"status":"ok","timestamp":1657819328219,"user_tz":240,"elapsed":758654,"user":{"displayName":"Benjamin Villegas","userId":"01591488523797727177"}},"outputId":"91854799-b9ba-46ea-ceb1-a93b4f5972f1"},"execution_count":207,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","215/215 [==============================] - 26s 76ms/step - loss: 3.2296 - accuracy: 0.1736 - val_loss: 2.1025 - val_accuracy: 0.1491\n","215/215 [==============================] - 15s 71ms/step - loss: 1.9095 - accuracy: 0.2025 - val_loss: 1.9421 - val_accuracy: 0.1733\n","Epoch 3/50\n","215/215 [==============================] - 15s 69ms/step - loss: 1.9029 - accuracy: 0.2012 - val_loss: 1.9009 - val_accuracy: 0.1748\n","Epoch 4/50\n","215/215 [==============================] - 16s 74ms/step - loss: 1.8979 - accuracy: 0.1927 - val_loss: 1.9009 - val_accuracy: 0.1723\n","Epoch 5/50\n","215/215 [==============================] - 15s 70ms/step - loss: 1.8911 - accuracy: 0.2022 - val_loss: 1.8999 - val_accuracy: 0.1723\n","Epoch 6/50\n","215/215 [==============================] - 15s 70ms/step - loss: 1.8845 - accuracy: 0.2000 - val_loss: 1.9012 - val_accuracy: 0.1733\n","Epoch 7/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.8823 - accuracy: 0.2096 - val_loss: 1.9122 - val_accuracy: 0.1614\n","Epoch 8/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8743 - accuracy: 0.2168 - val_loss: 1.9204 - val_accuracy: 0.1748\n","Epoch 9/50\n","215/215 [==============================] - 15s 67ms/step - loss: 1.8667 - accuracy: 0.2185 - val_loss: 1.9045 - val_accuracy: 0.1748\n","Epoch 10/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8645 - accuracy: 0.2284 - val_loss: 1.9992 - val_accuracy: 0.1733\n","Epoch 11/50\n","215/215 [==============================] - 14s 65ms/step - loss: 1.8577 - accuracy: 0.2265 - val_loss: 1.9323 - val_accuracy: 0.1642\n","Epoch 12/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8574 - accuracy: 0.2329 - val_loss: 1.9952 - val_accuracy: 0.1642\n","Epoch 13/50\n","215/215 [==============================] - 16s 73ms/step - loss: 1.8616 - accuracy: 0.2264 - val_loss: 12.5096 - val_accuracy: 0.1723\n","Epoch 14/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8519 - accuracy: 0.2330 - val_loss: 4.6070 - val_accuracy: 0.1723\n","Epoch 15/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.8444 - accuracy: 0.2411 - val_loss: 6.1406 - val_accuracy: 0.1723\n","Epoch 16/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.8472 - accuracy: 0.2401 - val_loss: 1.9285 - val_accuracy: 0.1748\n","Epoch 17/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.8391 - accuracy: 0.2388 - val_loss: 1.9473 - val_accuracy: 0.1733\n","Epoch 18/50\n","215/215 [==============================] - 15s 67ms/step - loss: 1.8359 - accuracy: 0.2447 - val_loss: 1.9727 - val_accuracy: 0.1733\n","Epoch 19/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.8294 - accuracy: 0.2515 - val_loss: 1.9068 - val_accuracy: 0.1748\n","Epoch 20/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.8188 - accuracy: 0.2525 - val_loss: 1.9085 - val_accuracy: 0.1748\n","Epoch 21/50\n","215/215 [==============================] - 16s 74ms/step - loss: 1.8216 - accuracy: 0.2539 - val_loss: 1.9115 - val_accuracy: 0.1748\n","Epoch 22/50\n","215/215 [==============================] - 15s 70ms/step - loss: 1.8134 - accuracy: 0.2519 - val_loss: 1.9145 - val_accuracy: 0.1748\n","Epoch 23/50\n","215/215 [==============================] - 15s 70ms/step - loss: 1.8183 - accuracy: 0.2544 - val_loss: 1.9143 - val_accuracy: 0.1748\n","Epoch 24/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.8173 - accuracy: 0.2548 - val_loss: 1.9138 - val_accuracy: 0.1769\n","Epoch 25/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8230 - accuracy: 0.2569 - val_loss: 2.9379 - val_accuracy: 0.1733\n","Epoch 26/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8113 - accuracy: 0.2584 - val_loss: 1.9194 - val_accuracy: 0.1748\n","Epoch 27/50\n","215/215 [==============================] - 15s 69ms/step - loss: 1.8044 - accuracy: 0.2580 - val_loss: 3.8823 - val_accuracy: 0.0587\n","Epoch 28/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.8009 - accuracy: 0.2580 - val_loss: 3.5616 - val_accuracy: 0.1733\n","Epoch 29/50\n","215/215 [==============================] - 16s 75ms/step - loss: 1.8017 - accuracy: 0.2643 - val_loss: 1.9202 - val_accuracy: 0.1741\n","Epoch 30/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.8015 - accuracy: 0.2645 - val_loss: 1.9197 - val_accuracy: 0.1748\n","Epoch 31/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7983 - accuracy: 0.2613 - val_loss: 2.3179 - val_accuracy: 0.1733\n","Epoch 32/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7953 - accuracy: 0.2706 - val_loss: 2.2770 - val_accuracy: 0.1733\n","Epoch 33/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.7926 - accuracy: 0.2691 - val_loss: 1.9242 - val_accuracy: 0.1748\n","Epoch 34/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.7955 - accuracy: 0.2694 - val_loss: 2.6092 - val_accuracy: 0.1733\n","Epoch 35/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.7907 - accuracy: 0.2722 - val_loss: 3.3602 - val_accuracy: 0.1733\n","Epoch 36/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.7840 - accuracy: 0.2742 - val_loss: 4.7176 - val_accuracy: 0.0587\n","Epoch 37/50\n","215/215 [==============================] - 15s 70ms/step - loss: 1.7817 - accuracy: 0.2752 - val_loss: 5.7472 - val_accuracy: 0.0587\n","Epoch 38/50\n","215/215 [==============================] - 17s 78ms/step - loss: 1.7857 - accuracy: 0.2758 - val_loss: 5.2185 - val_accuracy: 0.0587\n","Epoch 39/50\n","215/215 [==============================] - 15s 69ms/step - loss: 1.7828 - accuracy: 0.2704 - val_loss: 1.9263 - val_accuracy: 0.1748\n","Epoch 40/50\n","215/215 [==============================] - 15s 69ms/step - loss: 1.7807 - accuracy: 0.2752 - val_loss: 8.3073 - val_accuracy: 0.0587\n","Epoch 41/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.7805 - accuracy: 0.2710 - val_loss: 1.9286 - val_accuracy: 0.1751\n","Epoch 42/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.7701 - accuracy: 0.2758 - val_loss: 4.3049 - val_accuracy: 0.1733\n","Epoch 43/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.7721 - accuracy: 0.2813 - val_loss: 5.5365 - val_accuracy: 0.0587\n","Epoch 44/50\n","215/215 [==============================] - 15s 68ms/step - loss: 1.7755 - accuracy: 0.2779 - val_loss: 10.2131 - val_accuracy: 0.0587\n","Epoch 45/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7658 - accuracy: 0.2868 - val_loss: 15.7505 - val_accuracy: 0.0587\n","Epoch 46/50\n","215/215 [==============================] - 16s 73ms/step - loss: 1.7735 - accuracy: 0.2797 - val_loss: 11.4667 - val_accuracy: 0.1712\n","Epoch 47/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7630 - accuracy: 0.2845 - val_loss: 1.9427 - val_accuracy: 0.1762\n","Epoch 48/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7650 - accuracy: 0.2854 - val_loss: 18.7449 - val_accuracy: 0.0587\n","Epoch 49/50\n","215/215 [==============================] - 14s 67ms/step - loss: 1.7569 - accuracy: 0.2930 - val_loss: 18.8178 - val_accuracy: 0.0587\n","Epoch 50/50\n","215/215 [==============================] - 14s 66ms/step - loss: 1.7621 - accuracy: 0.2862 - val_loss: 15.3212 - val_accuracy: 0.1723\n"]}]}]}